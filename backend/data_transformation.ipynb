{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9fd5a10",
   "metadata": {},
   "source": [
    "# **Data Transformation**\n",
    "\n",
    "*This is where we do data wrangling and EDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22084d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from typing import Optional, Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d387894",
   "metadata": {},
   "source": [
    "# **1. Alcohol Consumption, BMI, Dietary, Smoking and Vaping**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683f88c",
   "metadata": {},
   "source": [
    "Based on \"Alcohol_Consumption\", for SQL, we need a tidy format where each row is one observation:\n",
    "- `alco_sex`: gender (\"Persons\", \"Males\", \"Females\")\n",
    "- `alco_category_group`: high-level grouping (e.g. \"Exceeded guideline(e)\", \"Did not exceed guideline\", etc.)\n",
    "- `alco_category`: specific measure under that group (e.g. \"Consumed more than 10 drinks in the last week\", \"Consumed 5 or more drinks on any day...\", \"Total exceeded guideline\")\n",
    "- `alco_age_group`: demographic column from the headers (e.g. \"15–17(c)\", \"18–24\", \"25–34\", \"65 years and over\", \"Total 18 years and over\")\n",
    "- `alco_estimate_000`: the numeric value in the table (population count in '000s)\n",
    "\n",
    "Similarly for all other files since they have same formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd20676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_estimates_file(file_path: str, prefix: str, output_path: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Read an Excel file that contains a survey 'Estimates' sheet, clean it, reshape to tidy format,\n",
    "    and write out a CSV. Returns the path to the written CSV.\n",
    "\n",
    "    Steps:\n",
    "      1) Open the first sheet whose name contains 'Estimates' (case-insensitive).\n",
    "      2) Remove metadata block (from the row starting with '* estimate' through the row containing\n",
    "         '© Commonwealth of Australia', case-insensitive, inclusive).\n",
    "      3) Auto-detect the header (age groups) row and promote it to column headers:\n",
    "         - If a row in col0 contains 'Age group', use the *next* row as the header row.\n",
    "         - Else, among the first ~10 rows, pick the row with the most non-null values across cols 1:.\n",
    "      4) Drop completely empty columns/rows.\n",
    "      5) Strip footnote markers like '(a)'..'(h)' anywhere in the sheet contents.\n",
    "      6) Identify structural section headers:\n",
    "         - '<prefix>_sex' section headers: 'Persons', 'Males', 'Females' (case-insensitive).\n",
    "         - '<prefix>_category_group' headers: any row with all-NaN across age columns and not a sex header.\n",
    "         Forward-fill both downwards.\n",
    "      7) Keep only data rows (i.e., not section headers), rename the first column to '<prefix>_category'.\n",
    "      8) Melt to tidy format with columns:\n",
    "         '<prefix>_sex', '<prefix>_category_group', '<prefix>_category',\n",
    "         '<prefix>_age_group', '<prefix>_estimate_000'\n",
    "      9) Write CSV to `output_path` (or f'{prefix}_tidy.csv' if not provided).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- helpers ----\n",
    "    def _find_estimates_sheet(xls: pd.ExcelFile) -> str:\n",
    "        for s in xls.sheet_names:\n",
    "            if \"estimates\" in s.lower() or \"estimate\" in s.lower():\n",
    "                return s\n",
    "        # fallback: use the first sheet if none matched\n",
    "        return xls.sheet_names[0]\n",
    "\n",
    "    def _remove_metadata_block(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Detect block in first column that starts with '* estimate' and ends with '© Commonwealth of Australia'.\n",
    "        Remove those rows inclusively. If not found, return df unchanged.\n",
    "        \"\"\"\n",
    "        if df.empty:\n",
    "            return df\n",
    "        first_col_name = df.columns[0]\n",
    "        first_col = df[first_col_name].astype(str).str.strip()\n",
    "\n",
    "        start_mask = first_col.str.lower().str.startswith(\"* estimate\")\n",
    "        end_mask = first_col.str.lower().str.contains(\"commonwealth of australia\")\n",
    "\n",
    "        start_idxs = df.index[start_mask].to_list()\n",
    "        end_idxs = df.index[end_mask].to_list()\n",
    "        if not start_idxs or not end_idxs:\n",
    "            return df\n",
    "\n",
    "        start_idx = start_idxs[0]\n",
    "        # choose the last '© Commonwealth...' that occurs after start, else the first one\n",
    "        end_idx_candidates = [i for i in end_idxs if i >= start_idx]\n",
    "        end_idx = (end_idx_candidates[-1] if end_idx_candidates else end_idxs[0])\n",
    "\n",
    "        # Drop inclusive block\n",
    "        return df.drop(index=range(start_idx, end_idx + 1), errors=\"ignore\")\n",
    "\n",
    "    def _auto_header_row(df: pd.DataFrame) -> int:\n",
    "        \"\"\"\n",
    "        Return the row index that contains the age group labels across columns 1:.\n",
    "        Heuristics:\n",
    "          - If a row's first column contains 'Age group' → header is the next row.\n",
    "          - Else choose the row (within first ~10) with the max non-null count in columns 1:.\n",
    "        \"\"\"\n",
    "        if df.empty:\n",
    "            return 0\n",
    "        first_col_name = df.columns[0]\n",
    "\n",
    "        # Look for \"Age group\" marker\n",
    "        col0 = df[first_col_name].astype(str).str.lower()\n",
    "        marker_rows = df.index[col0.str.contains(\"age group\", na=False)].to_list()\n",
    "        if marker_rows:\n",
    "            candidate = marker_rows[0] + 1\n",
    "            if candidate < len(df):\n",
    "                return candidate\n",
    "\n",
    "        # Fallback: densest non-null row across cols 1: within first 10 rows\n",
    "        lookahead = min(10, len(df))\n",
    "        sub = df.iloc[:lookahead, 1:]\n",
    "        nn = sub.notna().sum(axis=1)\n",
    "        return int(nn.idxmax())\n",
    "\n",
    "    def _strip_footnote_markers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Remove footnote markers like (a) .. (h) from all string cells.\"\"\"\n",
    "        footnote_re = re.compile(r\"\\(([a-hA-H])\\)\")\n",
    "        def clean_cell(x):\n",
    "            if isinstance(x, str):\n",
    "                return footnote_re.sub(\"\", x).strip()\n",
    "            return x\n",
    "        return df.map(clean_cell)\n",
    "    \n",
    "    def _strip_footnote_markers_list(values: List[str]) -> List[str]:\n",
    "        \"\"\"Remove footnote markers like (a) .. (h) from a list of strings.\"\"\"\n",
    "        footnote_re = re.compile(r\"\\(([a-hA-H])\\)\")\n",
    "        return [footnote_re.sub(\"\", str(v)).strip() for v in values]\n",
    "\n",
    "    # ---- load ----\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    sheet = _find_estimates_sheet(xls)\n",
    "    df = pd.read_excel(xls, sheet_name=sheet, header=None)  # no header yet; we’ll set it\n",
    "    # Drop fully empty rows/cols early\n",
    "    df = df.dropna(how=\"all\").dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # ---- remove metadata block by content, not index ----\n",
    "    df = _remove_metadata_block(df)\n",
    "    df = df.dropna(how=\"all\").dropna(axis=1, how=\"all\")  # re-trim\n",
    "\n",
    "    # ---- detect and promote header row ----\n",
    "    header_row_idx = _auto_header_row(df)\n",
    "    \n",
    "    # Extract and clean age group labels\n",
    "    age_labels_raw = df.iloc[header_row_idx, 1:].fillna(\"\").tolist()\n",
    "    age_labels = _strip_footnote_markers_list(age_labels_raw)\n",
    "\n",
    "    # Set cleaned column names\n",
    "    new_cols = [f\"{prefix}_row_label\"] + age_labels\n",
    "    df.columns = new_cols\n",
    "\n",
    "    # Drop rows up through the header row (they’re not data rows)\n",
    "    df = df.iloc[header_row_idx + 1 :].reset_index(drop=True)\n",
    "\n",
    "    # Strip footnote markers in all cells (e.g., \"(a)\"..\"(h)\")\n",
    "    df = _strip_footnote_markers(df)\n",
    "\n",
    "    # Ensure no fully empty columns remain\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    \n",
    "    # ---- identify structure rows ----\n",
    "    age_cols: List[str] = [c for c in df.columns if c != f\"{prefix}_row_label\"]\n",
    "    # A \"header row\" has all NaN across age columns\n",
    "    is_header_row = df[age_cols].isna().all(axis=1)\n",
    "\n",
    "    # Sex section headers\n",
    "    sex_values = {\"persons\", \"males\", \"females\", \"male\", \"female\"}  # a bit more tolerant\n",
    "    rl_lower = df[f\"{prefix}_row_label\"].astype(str).str.strip().str.lower()\n",
    "    is_sex_header = is_header_row & rl_lower.isin(sex_values)\n",
    "\n",
    "    # Category-group headers: header rows that are not sex headers\n",
    "    is_group_header = is_header_row & ~is_sex_header\n",
    "\n",
    "    # ---- forward-fill sex and category group ----\n",
    "    df[f\"{prefix}_sex\"] = pd.NA\n",
    "    df.loc[is_sex_header, f\"{prefix}_sex\"] = df.loc[is_sex_header, f\"{prefix}_row_label\"]\n",
    "    df[f\"{prefix}_sex\"] = df[f\"{prefix}_sex\"].ffill()\n",
    "\n",
    "    df[f\"{prefix}_category_group\"] = pd.NA\n",
    "    df.loc[is_group_header, f\"{prefix}_category_group\"] = df.loc[is_group_header, f\"{prefix}_row_label\"]\n",
    "    df[f\"{prefix}_category_group\"] = df[f\"{prefix}_category_group\"].ffill()\n",
    "\n",
    "    # ---- keep only data rows (not structural headers) ----\n",
    "    data = df.loc[~is_header_row].copy()\n",
    "    data = data.rename(columns={f\"{prefix}_row_label\": f\"{prefix}_category\"})\n",
    "\n",
    "    # ---- melt to tidy ----\n",
    "    tidy = data.melt(\n",
    "        id_vars=[f\"{prefix}_sex\", f\"{prefix}_category_group\", f\"{prefix}_category\"],\n",
    "        value_vars=age_cols,\n",
    "        var_name=f\"{prefix}_age_group\",\n",
    "        value_name=f\"{prefix}_estimate_000\"\n",
    "    )\n",
    "\n",
    "    # clean values\n",
    "    tidy[f\"{prefix}_estimate_000\"] = pd.to_numeric(tidy[f\"{prefix}_estimate_000\"], errors=\"coerce\")\n",
    "    tidy = tidy.dropna(subset=[f\"{prefix}_estimate_000\"]).reset_index(drop=True)\n",
    "\n",
    "    # order columns\n",
    "    tidy = tidy[\n",
    "        [f\"{prefix}_sex\", f\"{prefix}_category_group\", f\"{prefix}_category\",\n",
    "         f\"{prefix}_age_group\", f\"{prefix}_estimate_000\"]]\n",
    "    \n",
    "        # ---- special handling for smoking table ----\n",
    "        # ---- special handling for smoking table (fix only the \"Current smoker\" group) ----\n",
    "    if prefix == \"smoke\":\n",
    "        sex_col = f\"{prefix}_sex\"\n",
    "        grp_col = f\"{prefix}_category_group\"\n",
    "        cat_col = f\"{prefix}_category\"\n",
    "        age_col = f\"{prefix}_age_group\"\n",
    "        est_col = f\"{prefix}_estimate_000\"\n",
    "\n",
    "        # normalized helpers\n",
    "        grp_norm = tidy[grp_col].astype(str).str.strip().str.lower()\n",
    "        cat_norm = (\n",
    "            tidy[cat_col].astype(str).str.strip().str.lower()\n",
    "            .str.replace(\",\", \"\", regex=False)\n",
    "            .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        )\n",
    "\n",
    "        # rows that are currently under the \"Current smoker\" group\n",
    "        in_current_group = grp_norm.eq(\"current smoker\")\n",
    "\n",
    "        # (A) Build \"Current smoker\" category from \"Total current smoker(c)\" rows\n",
    "        mask_total_current = in_current_group & cat_norm.str.startswith(\"total current smoker\")\n",
    "        current_rows = tidy.loc[mask_total_current, [sex_col, age_col, est_col]].copy()\n",
    "        current_rows[grp_col] = \"Smoker status\"\n",
    "        current_rows[cat_col] = \"Current smoker\"\n",
    "\n",
    "        # (B) Keep the other three categories from the same group\n",
    "        keep_map = {\n",
    "            \"ex-smoker\": \"Ex-smoker\",\n",
    "            \"never smoked\": \"Never smoked\",\n",
    "            \"total persons aged 15 years and over\": \"Total persons aged 15 years and over\",\n",
    "            \"total persons 15 years and over\": \"Total persons aged 15 years and over\",  # tolerate punctuation variants\n",
    "        }\n",
    "        mask_keep_three = in_current_group & cat_norm.isin(keep_map.keys())\n",
    "        keep_rows = tidy.loc[mask_keep_three, [sex_col, age_col, est_col]].copy()\n",
    "        # set target casing and group name\n",
    "        keep_rows[cat_col] = cat_norm[mask_keep_three].map(keep_map)\n",
    "        keep_rows[grp_col] = \"Smoker status\"\n",
    "\n",
    "        # (C) All other rows (NOT in the \"Current smoker\" group) stay as-is\n",
    "        other_rows = tidy.loc[~in_current_group].copy()\n",
    "\n",
    "        # (D) Concatenate back together\n",
    "        tidy = pd.concat([other_rows, current_rows, keep_rows], ignore_index=True)\n",
    "\n",
    "        # Reorder columns just in case\n",
    "        tidy = tidy[[sex_col, grp_col, cat_col, age_col, est_col]]\n",
    "\n",
    "    # ---- write CSV ----\n",
    "    if output_path is None:\n",
    "        output_path = f\"{prefix}_tidy.csv\"\n",
    "    tidy.to_csv(output_path, index=False)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a529f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: alco_tidy.csv\n",
      "Wrote: smoke_tidy.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = process_estimates_file(\"datasets/Alcohol_Consumption.xlsx\", prefix=\"alco\")\n",
    "print(\"Wrote:\", csv_path)\n",
    "\n",
    "csv_path = process_estimates_file(\"datasets/Smoking_and_Vaping.xlsx\", prefix=\"smoke\")\n",
    "print(\"Wrote:\", csv_path)\n",
    "\n",
    "# csv_path = process_estimates_file(\"datasets/BMI.xlsx\", prefix=\"bmi\")\n",
    "# print(\"Wrote:\", csv_path)\n",
    "\n",
    "# csv_path = process_estimates_file(\"datasets/Dietary_Behaviour.xlsx\", prefix=\"diet\")\n",
    "# print(\"Wrote:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad4e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
